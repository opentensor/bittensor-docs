

<!DOCTYPE html>
<html class="writer-html4" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Running Multiple Bittensor Instances &mdash; Bittensor 1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="gRPC Protocol" href="../bittensor-deep-dive/grpc_protocol.html" />
    <link rel="prev" title="Run Bittensor via Python" href="run-bittensor-via-python.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Bittensor
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="run-bittensor-via-docker.html">Run Bittensor via Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="run-bittensor-via-python.html">Run Bittensor via Python</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Running Multiple Bittensor Instances</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#via-dockerized-containers">Via Dockerized Containers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#via-native-python">Via Native Python</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Bittensor Architecture</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bittensor-deep-dive/grpc_protocol.html">gRPC Protocol</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Bittensor</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Running Multiple Bittensor Instances</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/crate/crate-docs-theme/blob/master/docs/getting-started/run-multiple-bittensor-instances.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="running-multiple-bittensor-instances">
<h1>Running Multiple Bittensor Instances<a class="headerlink" href="#running-multiple-bittensor-instances" title="Permalink to this headline">¶</a></h1>
<p>The advantage of Bittensor is that it allows for <em>knowledge sharing</em> between models training together. This not only allows for more efficient training,
but also increases the possibilities for us to develop resilient generalist models, as opposed to narrow specialists.</p>
<p>Let’s dive into how we can test running two models at the same time that can share knowledge with each other as they train. Bittensor utilizes
<a class="reference external" href="https://grpc.io/">gRPC</a> communication to send <a class="reference external" href="http://www.pythonware.com/products/pil/">PIL</a> data, tensors,
and gradients across the wire from one model to another model (also called a “peer”). We will first show how we can achieve this using Docker containers, and
then show the same process using native Python commands.</p>
<p>Each Bittensor instance (native Python or Dockerized) requires some specific ports to be opened up for it to be able to communicate
with other instances. These are:</p>
<p>1. <strong>Axon Port</strong> : This port is where communications are received. If it is not opened, then your bittensor instance cannot receive gRPC communications
from its peers. This is automatically exposed on a random port number on the Docker container via the <code class="code docutils literal notranslate"><span class="pre">start_bittensor.sh</span></code> script if
running on Docker, and via Python as well if running on native Python. Hence, there is typically no need to set it yourself unless
you are going after some rather specific architectural setup for your network.</p>
<p>2. <strong>Metagraph Port</strong> : This port is largely for testing purposes, and is responsible for specifying which metagraph port to connect to.
In a nutshell, the metagraph is the connecting fabric between all the nodes/models and acts as a “simulated” chain when a blockchain is not present.
When testing locally, the first instance you run needs to specify its metagraph port.</p>
<p>3. <strong>Bootstrap port</strong> : When testing, each node will need to bootstrap itself to a peer so they can begin the communication process. When
testing locally on Docker, the IP of this peer automatically resolves to <code class="code docutils literal notranslate"><span class="pre">host.docker.internal</span></code>. When testing via native Python,
the IP is specified as <code class="code docutils literal notranslate"><span class="pre">0.0.0.0</span></code>. When testing locally, this port needs to be set to be the same as the metagraph port that the
first instance you launched is using.</p>
<div class="section" id="via-dockerized-containers">
<h2>Via Dockerized Containers<a class="headerlink" href="#via-dockerized-containers" title="Permalink to this headline">¶</a></h2>
<p>To run multiple instances via Docker containers, we must expose the Axon, Metagraph, and Bootstrap ports. We must also first create an instance
that binds itself to the Metagraph via a given port, and the second instance must then bootstrap itself to the first instance to
begin communication.</p>
<p>Let’s start by running the first instance and binding it to metagraph port <code class="code docutils literal notranslate"><span class="pre">8120</span></code>.</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>./start_bittensor.sh -m <span class="m">8120</span>
</pre></div>
</div>
<p>This starts a Dockerized instance of Bittensor bound to metagraph port <code class="code docutils literal notranslate"><span class="pre">8120</span></code> without a bootstrapped peer.</p>
<p>The training output for each iteration will look like the following:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="m">2020</span>-10-06 <span class="m">14</span>:21:59.100 <span class="p">|</span> INFO     <span class="p">|</span> __main__:train:291 - Train Epoch: <span class="m">0</span> <span class="o">[</span><span class="m">0</span>/60000 <span class="o">(</span><span class="m">0</span>%<span class="o">)]</span>     Local Loss: <span class="m">2</span>.306969    Target Loss: <span class="m">2</span>.306806   Distillation Loss: <span class="m">0</span>.027752     nP<span class="p">|</span>nS: <span class="m">0</span><span class="p">|</span><span class="m">1</span>
</pre></div>
</div>
<p>Note that the very last values of this line: <code class="code docutils literal notranslate"><span class="pre">nP|nS:</span> <span class="pre">0|1</span></code>. This indicates the number of peers (<code class="code docutils literal notranslate"><span class="pre">nP</span></code>) and the number of Synapses (<code class="code docutils literal notranslate"><span class="pre">nS</span></code>), at the moment there are no peers
and one synapse that belongs to this instance that we’ve just launched.</p>
<p>Now let’s launch another instance that will communicate with the initial instance we just launched. The appropriate bootstrap IP is
automatically determined when running locally, so we just need to specify the <code class="code docutils literal notranslate"><span class="pre">bootstrap_port</span></code>. Open another terminal and run the following call:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>./start_bittensor.sh -b <span class="m">8120</span>
</pre></div>
</div>
<p>Now if we take a look at the training output, note that <code class="code docutils literal notranslate"><span class="pre">nP</span></code> and <code class="code docutils literal notranslate"><span class="pre">nS</span></code> changed to <code class="code docutils literal notranslate"><span class="pre">nP|nS:</span> <span class="pre">1|2</span></code> as there is one peer and two synapses firing now.</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="m">2020</span>-10-06 <span class="m">14</span>:22:08.616 <span class="p">|</span> INFO     <span class="p">|</span> __main__:train:291 - Train Epoch: <span class="m">0</span> <span class="o">[</span><span class="m">0</span>/60000 <span class="o">(</span><span class="m">0</span>%<span class="o">)]</span>     Local Loss: <span class="m">2</span>.299487    Target Loss: <span class="m">2</span>.299433   Distillation Loss: <span class="m">0</span>.038577     nP<span class="p">|</span>nS: <span class="m">1</span><span class="p">|</span><span class="m">2</span>
</pre></div>
</div>
<p>This indicates that our new instance has bootstrapped successfully to the first instance that we launched, and is communicating with it appropriately.</p>
</div>
<div class="section" id="via-native-python">
<h2>Via Native Python<a class="headerlink" href="#via-native-python" title="Permalink to this headline">¶</a></h2>
<p>The process to run multiple instances via native Python is very similar to the Dockerized example, the only difference being the syntax of the
command line arguments as we are sending them directly to Python in this case. As in the Docker container example, we first create an instance
that binds itself to the Metagraph via a given port, and the second instance must then bootstrap itself to the first instance to
begin communication.</p>
<p>Let’s start by running the first instance and binding it to metagraph port <code class="code docutils literal notranslate"><span class="pre">8120</span></code>.</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>python3 examples/mnist/main.py --metagraph_port<span class="o">=</span><span class="m">8120</span>
</pre></div>
</div>
<p>Now let’s launch another instance that will communicate with the initial instance we just launched. The difference from Docker, however,
is that the appropriate bootstrap IP is <strong>not</strong> determined automatically now, so we must specify it along with the bootstrap port. Open
another terminal and run the following call:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span>python3 ./examples/mnist/main.py --bootstrap<span class="o">=</span><span class="s1">&#39;0.0.0.0:8120&#39;</span>
</pre></div>
</div>
<p>The output from the training loops both instances will be the same as the dockerized versions:</p>
<p>The training output for each iteration of the first instance will look like the following:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="m">2020</span>-10-06 <span class="m">14</span>:21:59.100 <span class="p">|</span> INFO     <span class="p">|</span> __main__:train:291 - Train Epoch: <span class="m">0</span> <span class="o">[</span><span class="m">0</span>/60000 <span class="o">(</span><span class="m">0</span>%<span class="o">)]</span>     Local Loss: <span class="m">2</span>.306969    Target Loss: <span class="m">2</span>.306806   Distillation Loss: <span class="m">0</span>.027752     nP<span class="p">|</span>nS: <span class="m">0</span><span class="p">|</span><span class="m">1</span>
</pre></div>
</div>
<p>whereas the training output for each iteration of the second (boostrapped) instance will look like:</p>
<div class="highlight-Bash notranslate"><div class="highlight"><pre><span></span><span class="m">2020</span>-10-06 <span class="m">14</span>:22:08.616 <span class="p">|</span> INFO     <span class="p">|</span> __main__:train:291 - Train Epoch: <span class="m">0</span> <span class="o">[</span><span class="m">0</span>/60000 <span class="o">(</span><span class="m">0</span>%<span class="o">)]</span>     Local Loss: <span class="m">2</span>.299487    Target Loss: <span class="m">2</span>.299433   Distillation Loss: <span class="m">0</span>.038577     nP<span class="p">|</span>nS: <span class="m">1</span><span class="p">|</span><span class="m">2</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../bittensor-deep-dive/grpc_protocol.html" class="btn btn-neutral float-right" title="gRPC Protocol" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="run-bittensor-via-python.html" class="btn btn-neutral float-left" title="Run Bittensor via Python" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Ala Shaabana, Jacob Steeves, and the Bittensor community

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>